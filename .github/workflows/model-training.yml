name: MLflow CI/CD Model Training

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'MLproject/**'
      - '.github/workflows/**'
      - '*.py'
      - '*.yaml'
      - '*.yml'
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      experiment_name:
        description: 'MLflow experiment name'
        required: false
        default: 'iris_classification_ci_alpian_khairi'
      n_estimators:
        description: 'Number of estimators'
        required: false
        default: '100'
      max_depth:
        description: 'Maximum depth'
        required: false
        default: '10'
      use_remote_tracking:
        description: 'Use DagsHub remote tracking (true/false)'
        required: false
        default: 'false'
        type: choice
        options:
        - 'true'
        - 'false'

jobs:
  model-training:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Debug - List project structure
      run: |
        echo "Root directory contents:"
        ls -la
        echo "MLproject directory contents (if exists):"
        ls -la MLproject/ || echo "MLproject directory not found"
        echo "Looking for required files..."
        find . -name "conda.yaml" -o -name "MLProject" -o -name "modelling.py" | head -20
        
    - name: Verify required files exist
      run: |
        echo "Checking for required files..."
        
        # Check conda.yaml
        if [ -f MLproject/conda.yaml ]; then
          echo "âœ… conda.yaml found!"
          echo "conda.yaml content:"
          cat MLproject/conda.yaml
        else
          echo "âŒ conda.yaml not found!"
          exit 1
        fi
        
        # Check MLProject
        if [ -f MLproject/MLProject ]; then
          echo "âœ… MLProject file found!"
          echo "MLProject file content:"
          cat MLproject/MLProject
        else
          echo "âŒ MLProject file not found!"
          exit 1
        fi
        
        # Check modelling.py
        if [ -f MLproject/modelling.py ]; then
          echo "âœ… modelling.py found!"
        else
          echo "âŒ modelling.py not found!"
          exit 1
        fi
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        echo "Installing core dependencies..."
        pip install numpy==1.24.4 pandas==2.1.4 scikit-learn==1.3.2 
        pip install matplotlib==3.8.2 seaborn==0.13.0
        pip install mlflow==2.8.1 dagshub python-dotenv joblib
        pip install requests urllib3
        
    - name: Verify Python environment
      run: |
        echo "Python version:"
        python --version
        echo "Installed packages:"
        pip list | grep -E "(numpy|pandas|scikit-learn|matplotlib|seaborn|mlflow|dagshub|joblib)" || echo "Some packages might be missing"
        echo "Python path:"
        python -c "import sys; print('\\n'.join(sys.path))"
        
    - name: Test imports
      run: |
        echo "Testing critical imports..."
        python -c "import numpy; print(f'NumPy: {numpy.__version__}')"
        python -c "import pandas; print(f'Pandas: {pandas.__version__}')"
        python -c "import sklearn; print(f'Scikit-learn: {sklearn.__version__}')"
        python -c "import matplotlib; print(f'Matplotlib: {matplotlib.__version__}')"
        python -c "import seaborn; print(f'Seaborn: {seaborn.__version__}')"
        python -c "import mlflow; print(f'MLflow: {mlflow.__version__}')"
        python -c "import dagshub; print('DagsHub: OK')"
        python -c "import joblib; print(f'Joblib: {joblib.__version__}')"
        
    - name: Setup Miniconda (optional - for MLflow conda env)
      uses: conda-incubator/setup-miniconda@v3
      with:
        miniconda-version: "latest"
        activate-environment: iris-classification-env
        environment-file: ./MLproject/conda.yaml
        python-version: 3.9
        auto-activate-base: false
        auto-update-conda: true
      continue-on-error: true
      
    - name: Set up environment variables
      run: |
        # Set environment variables for both local and remote tracking
        echo "PYTHONPATH=$GITHUB_WORKSPACE:$GITHUB_WORKSPACE/MLproject:$PYTHONPATH" >> $GITHUB_ENV
        echo "MLFLOW_TRACKING_INSECURE_TLS=true" >> $GITHUB_ENV
        echo "MLFLOW_HTTP_REQUEST_TIMEOUT=30" >> $GITHUB_ENV
        echo "MLFLOW_HTTP_REQUEST_MAX_RETRIES=3" >> $GITHUB_ENV
        
        # Only set DagsHub credentials if token is available and remote tracking is requested
        if [ "${{ secrets.DAGSHUB_TOKEN }}" != "" ] && [ "${{ github.event.inputs.use_remote_tracking }}" == "true" ]; then
          echo "DAGSHUB_TOKEN=${{ secrets.DAGSHUB_TOKEN }}" >> $GITHUB_ENV
          echo "MLFLOW_TRACKING_USERNAME=alvian2022" >> $GITHUB_ENV
          echo "MLFLOW_TRACKING_PASSWORD=${{ secrets.DAGSHUB_TOKEN }}" >> $GITHUB_ENV
          echo "REMOTE_TRACKING_ENABLED=true" >> $GITHUB_ENV
        else
          echo "REMOTE_TRACKING_ENABLED=false" >> $GITHUB_ENV
          echo "â„¹ï¸ Remote tracking disabled - using local MLflow tracking"
        fi
        
    - name: Change to project directory and prepare data
      run: |
        cd MLproject
        echo "Changed to project directory: $(pwd)"
        echo "Files in current directory:"
        ls -la
        
        # Create sample data if it doesn't exist
        python -c "
        import pandas as pd
        from sklearn.datasets import load_iris
        import os

        # Create sample data if iris_preprocessing.csv doesn't exist
        if not os.path.exists('iris_preprocessing.csv'):
            print('Creating sample iris dataset...')
            iris = load_iris()
            df = pd.DataFrame(iris.data, columns=iris.feature_names)
            df['target'] = iris.target
            df.to_csv('iris_preprocessing.csv', index=False)
            print('Sample data created: iris_preprocessing.csv')
            print(f'Data shape: {df.shape}')
            print(f'Columns: {list(df.columns)}')
            print(f'Target distribution:\\n{df.target.value_counts()}')
        else:
            print('iris_preprocessing.csv already exists')
            df = pd.read_csv('iris_preprocessing.csv')
            print(f'Data shape: {df.shape}')
            print(f'Columns: {list(df.columns)}')
        "
        
    - name: Test DagsHub Connection (if remote tracking enabled)
      working-directory: ./MLproject
      run: |
        if [ "$REMOTE_TRACKING_ENABLED" == "true" ]; then
          echo "Testing DagsHub connection..."
          python -c "
          import os
          import requests
          from requests.adapters import HTTPAdapter
          from urllib3.util.retry import Retry

          try:
              session = requests.Session()
              retry_strategy = Retry(
                  total=3,
                  backoff_factor=1,
                  status_forcelist=[429, 500, 502, 503, 504],
              )
              adapter = HTTPAdapter(max_retries=retry_strategy)
              session.mount('http://', adapter)
              session.mount('https://', adapter)
              
              # Test DagsHub connection
              response = session.get('https://dagshub.com/alvian2022/iris-classification', timeout=10)
              if response.status_code == 200:
                  print('âœ… DagsHub connection successful')
              else:
                  print(f'âš ï¸ DagsHub returned status code: {response.status_code}')
                  print('Switching to local tracking...')
                  os.environ['REMOTE_TRACKING_ENABLED'] = 'false'
          except Exception as e:
              print(f'âŒ DagsHub connection failed: {e}')
              print('Switching to local tracking...')
              os.environ['REMOTE_TRACKING_ENABLED'] = 'false'
          "
        else
          echo "â„¹ï¸ Remote tracking disabled - using local MLflow tracking"
        fi
        
    - name: Run Direct Python Training (Primary Method)
      working-directory: ./MLproject
      run: |
        echo "ğŸš€ Starting model training..."
        echo "Training Configuration:"
        echo "  - Remote Tracking: $REMOTE_TRACKING_ENABLED"
        echo "  - Experiment: ${{ github.event.inputs.experiment_name || 'iris_classification_ci_alpian_khairi' }}"
        echo "  - N Estimators: ${{ github.event.inputs.n_estimators || 100 }}"
        echo "  - Max Depth: ${{ github.event.inputs.max_depth || 10 }}"
        
        # Run direct Python training with timeout
        timeout 600 python modelling.py \
          --data_path "iris_preprocessing.csv" \
          --experiment_name "${{ github.event.inputs.experiment_name || 'iris_classification_ci_alpian_khairi' }}" \
          --model_name "iris_classifier_ci" \
          --n_estimators ${{ github.event.inputs.n_estimators || 100 }} \
          --max_depth ${{ github.event.inputs.max_depth || 10 }} \
          --random_state 42 || {
            echo "âŒ Training failed or timed out after 10 minutes"
            echo "ğŸ“Š Checking for partial artifacts..."
            ls -la *.pkl *.png *.txt *.md *.csv 2>/dev/null || echo "No artifacts found"
            exit 1
          }
          
    - name: Run MLflow Project Training (Alternative Method)
      if: failure()
      working-directory: ./MLproject
      run: |
        echo "ğŸ”„ Trying MLflow project method as fallback..."
        
        # Try to activate conda environment if available
        if command -v conda &> /dev/null; then
          echo "Conda available, trying to activate environment..."
          eval "$(conda shell.bash hook)"
          conda activate iris-classification-env || echo "Conda activate failed, using pip environment"
        fi
        
        # Run the MLflow project using the training entry point
        timeout 600 mlflow run . \
          --entry-point training \
          --experiment-name "${{ github.event.inputs.experiment_name || 'iris_classification_ci_alpian_khairi' }}" \
          -P data_path="iris_preprocessing.csv" \
          -P n_estimators=${{ github.event.inputs.n_estimators || 100 }} \
          -P max_depth=${{ github.event.inputs.max_depth || 10 }} \
          -P random_state=42 \
          --env-manager local || {
            echo "âŒ MLflow project training also failed"
            exit 1
          }
      continue-on-error: true
        
    - name: Verify artifacts were created
      working-directory: ./MLproject
      run: |
        echo "ğŸ“ Checking for generated artifacts..."
        
        # Check for essential files
        ARTIFACTS_FOUND=false
        
        if [ -f "trained_model_ci.pkl" ]; then
          echo "âœ… Model file found: trained_model_ci.pkl"
          ARTIFACTS_FOUND=true
        fi
        
        if [ -f "confusion_matrix_ci.png" ]; then
          echo "âœ… Confusion matrix found: confusion_matrix_ci.png"
          ARTIFACTS_FOUND=true
        fi
        
        if [ -f "feature_importance_ci.png" ]; then
          echo "âœ… Feature importance plot found: feature_importance_ci.png"
          ARTIFACTS_FOUND=true
        fi
        
        if [ -f "classification_report_ci.txt" ]; then
          echo "âœ… Classification report found: classification_report_ci.txt"
          ARTIFACTS_FOUND=true
        fi
        
        if [ -f "training_summary.md" ]; then
          echo "âœ… Training summary found: training_summary.md"
          ARTIFACTS_FOUND=true
        fi
        
        echo "ğŸ“‚ All files in project directory:"
        ls -la
        
        echo "ğŸ“‚ Model artifacts directory:"
        ls -la model_artifacts/ || echo "No model_artifacts directory"
        
        echo "ğŸ“‚ MLruns directory:"
        ls -la mlruns/ || echo "No mlruns directory"
        
        if [ "$ARTIFACTS_FOUND" == "false" ]; then
          echo "âŒ No essential artifacts found - training may have failed"
          exit 1
        else
          echo "âœ… Essential artifacts found - training appears successful"
        fi
        
    - name: Display training results
      working-directory: ./MLproject
      run: |
        echo "ğŸ“Š Training Results Summary:"
        echo "=========================="
        
        # Display training summary if available
        if [ -f "training_summary.md" ]; then
          echo "ğŸ“„ Training Summary:"
          cat training_summary.md
        fi
        
        # Display classification report if available
        if [ -f "classification_report_ci.txt" ]; then
          echo "ğŸ“ˆ Classification Report:"
          cat classification_report_ci.txt
        fi
        
        # Show file sizes
        echo "ğŸ“ Generated Files:"
        ls -lh *.pkl *.png *.txt *.md *.csv 2>/dev/null || echo "No artifacts in main directory"
        
    - name: Upload training artifacts
      uses: actions/upload-artifact@v4
      with:
        name: model-artifacts-${{ github.run_number }}
        path: |
          MLproject/*.pkl
          MLproject/*.png
          MLproject/*.txt
          MLproject/*.md
          MLproject/*.csv
          MLproject/model_artifacts/
          MLproject/mlruns/
        retention-days: 30
        if-no-files-found: warn
        
    - name: Create workflow summary
      working-directory: ./MLproject
      run: |
        echo "# ğŸ¯ Training Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Workflow Run**: #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Timestamp**: $(date)" >> $GITHUB_STEP_SUMMARY
        echo "- **Parameters**: n_estimators=${{ github.event.inputs.n_estimators || 100 }}, max_depth=${{ github.event.inputs.max_depth || 10 }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Experiment**: ${{ github.event.inputs.experiment_name || 'iris_classification_ci_alpian_khairi' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Remote Tracking**: $REMOTE_TRACKING_ENABLED" >> $GITHUB_STEP_SUMMARY
        echo "- **Author**: alpian_khairi_C1BO" >> $GITHUB_STEP_SUMMARY
        
        echo "## ğŸ“ Generated Files" >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
        ls -la *.pkl *.png *.txt *.md *.csv 2>/dev/null || echo "No artifacts found in project directory"
        echo '```' >> $GITHUB_STEP_SUMMARY
        
        echo "## ğŸ“Š Training Results" >> $GITHUB_STEP_SUMMARY
        if [ -f "training_summary.md" ]; then
          echo "### Training Summary" >> $GITHUB_STEP_SUMMARY
          cat training_summary.md >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "classification_report_ci.txt" ]; then
          echo "### Classification Report" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat classification_report_ci.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi
        
        # Create a comprehensive summary file
        echo "=== MLflow CI/CD Training Summary ===" > training_summary.txt
        echo "Workflow Run: #${{ github.run_number }}" >> training_summary.txt
        echo "Commit: ${{ github.sha }}" >> training_summary.txt
        echo "Timestamp: $(date)" >> training_summary.txt
        echo "Parameters: n_estimators=${{ github.event.inputs.n_estimators || 100 }}, max_depth=${{ github.event.inputs.max_depth || 10 }}" >> training_summary.txt
        echo "Experiment: ${{ github.event.inputs.experiment_name || 'iris_classification_ci_alpian_khairi' }}" >> training_summary.txt
        echo "Remote Tracking: $REMOTE_TRACKING_ENABLED" >> training_summary.txt
        echo "Author: alpian_khairi_C1BO" >> training_summary.txt
        echo "Status: SUCCESS" >> training_summary.txt
        echo "" >> training_summary.txt
        echo "Generated Files:" >> training_summary.txt
        ls -la *.pkl *.png *.txt *.md *.csv 2>/dev/null >> training_summary.txt || echo "No artifacts found" >> training_summary.txt
        
    - name: Upload workflow summary
      uses: actions/upload-artifact@v4
      with:
        name: workflow-summary-${{ github.run_number }}
        path: MLproject/training_summary.txt
        retention-days: 30
        if-no-files-found: warn
        
    - name: Notify completion
      run: |
        echo "ğŸ‰ Training workflow completed successfully!"
        echo "ğŸ“Š Check the 'Actions' tab for detailed results and artifacts"
        echo "ğŸ“ Artifacts will be available for download for 30 days"
        if [ "$REMOTE_TRACKING_ENABLED" == "true" ]; then
          echo "ğŸŒ Remote tracking: Check DagsHub for experiment results"
          echo "   Repository: https://dagshub.com/alvian2022/iris-classification"
        else
          echo "ğŸ’» Local tracking: MLflow results stored in artifacts"
        fi